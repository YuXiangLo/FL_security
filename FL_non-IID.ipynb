{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-06-03T10:20:45.593888Z","iopub.status.busy":"2024-06-03T10:20:45.593560Z","iopub.status.idle":"2024-06-03T10:21:21.266614Z","shell.execute_reply":"2024-06-03T10:21:21.265488Z","shell.execute_reply.started":"2024-06-03T10:20:45.593859Z"},"id":"n7k3WQGm_MI7","outputId":"12ba59f3-01e0-4938-998d-b668dba9d882","trusted":true},"outputs":[],"source":["# ! rm -rf /opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info\n","%pip install -q 'flwr[simulation]' 'flwr_datasets[vision]' torch torchvision matplotlib"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T10:21:21.269885Z","iopub.status.busy":"2024-06-03T10:21:21.269006Z","iopub.status.idle":"2024-06-03T10:21:48.579575Z","shell.execute_reply":"2024-06-03T10:21:48.578758Z","shell.execute_reply.started":"2024-06-03T10:21:21.269845Z"},"id":"flOZJcq6_ieI","trusted":true},"outputs":[],"source":["from collections import OrderedDict\n","from typing import List, Tuple\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","from datasets.utils.logging import disable_progress_bar\n","from torch.utils.data import DataLoader\n","\n","import flwr as fl\n","from flwr.common import Metrics\n","\n","from typing import Optional, Dict\n","import os\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-06-03T10:21:48.580973Z","iopub.status.busy":"2024-06-03T10:21:48.580693Z","iopub.status.idle":"2024-06-03T10:21:48.643407Z","shell.execute_reply":"2024-06-03T10:21:48.642263Z","shell.execute_reply.started":"2024-06-03T10:21:48.580949Z"},"id":"_NDi81IU0P-_","outputId":"61ea9472-8184-4347-f338-5cd32f29a4c7","trusted":true},"outputs":[],"source":["config = {\n","    \"dataset\": \"cifar10\",\n","    \"num_clients\": 5,\n","    \"batch_size\": 32,\n","    \"poison_clients\": [],\n","\n","    # DO NOT SET ATTACK HERE !!!\n","    # \"poison_clients\": [],\n","    # \"poison_type\": \"one-label\",\n","    # \"poison_label\": 0,\n","    # \"poison_type\": \"label-flipping\",\n","    # \"poison_type\": \"label-random\",\n","    # \"poison_type\": \"DBA\",\n","    # \"poison_type\": \"CBA\",\n","    \"poison_type\": \"No-Attacks-For-Non-IID-Performance-Testing\",\n","    \n","    \"gamma\": 5,\n","    \"epochs\": 20,\n","    \"lr\": 0.05,\n","    \"momentum\": 0.9,\n","    \"weight_decay\": 0.0001,\n","    \"num_classes\": 10,\n","    \"input_size\": (3, 32, 32),\n","    \"seed\": 42, \n","}\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\n","    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",")\n","disable_progress_bar()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-06-03T10:21:48.647105Z","iopub.status.busy":"2024-06-03T10:21:48.646678Z","iopub.status.idle":"2024-06-03T10:31:20.415493Z","shell.execute_reply":"2024-06-03T10:31:20.414603Z","shell.execute_reply.started":"2024-06-03T10:21:48.647067Z"},"id":"rloDQlZ8_5xw","outputId":"684dd7de-336c-4a62-fa5f-4a3f1042cd98","trusted":true},"outputs":[],"source":["backdoor_idx = 0\n","from flwr_datasets import FederatedDataset\n","from flwr_datasets.partitioner import ShardPartitioner\n","partitioner = ShardPartitioner(num_partitions=config[\"num_clients\"], partition_by=\"label\", num_shards_per_partition=2)\n","\n","def load_datasets():\n","    fds = FederatedDataset(dataset=config[\"dataset\"], partitioners={\"train\": partitioner})\n","    print(len(fds.load_split(\"train\")))\n","    def apply_train_transforms(batch):\n","        # print(\"in apply_train_transforms\")\n","        # Instead of passing transforms to CIFAR10(..., transform=transform)\n","        # we will use this function to dataset.with_transform(apply_transforms)\n","        # The transforms object is exactly the same\n","        transform = transforms.Compose(\n","            [\n","                # transforms.RandomHorizontalFlip(),\n","                # transforms.RandomAffine(15, translate=(0.15, 0.15), scale=(0.9, 1.1), shear=10),\n","                # transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.05),\n","                transforms.ToTensor(),\n","                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","            ]\n","        )\n","        batch[\"img\"] = [transform(img) for img in batch[\"img\"]]\n","        return batch\n","\n","    def apply_val_transforms(batch):\n","        # Instead of passing transforms to CIFAR10(..., transform=transform)\n","        # we will use this function to dataset.with_transform(apply_transforms)\n","        # The transforms object is exactly the same\n","        # print(\"in apply_val_transforms\")\n","        transform = transforms.Compose(\n","            [\n","                transforms.ToTensor(),\n","                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","            ]\n","        )\n","        batch[\"img\"] = [transform(img) for img in batch[\"img\"]]\n","        return batch\n","\n","    def poisonTrainData(data):\n","        if config[\"poison_type\"] == \"one-label\":\n","            data[\"label\"] = config[\"poison_label\"]\n","        elif config[\"poison_type\"] == \"label-flipping\":\n","            data[\"label\"] = (data[\"label\"] + 1) % config[\"num_classes\"]\n","        elif config[\"poison_type\"] == \"label-random\":\n","            data[\"label\"] =  np.floor(np.random.rand() * config[\"num_classes\"])\n","        elif config[\"poison_type\"] == \"CBA\":\n","            data[\"img\"] = np.array(data[\"img\"])\n","            data[\"img\"][0:2, 0:2, :] = 0\n","            data[\"img\"][0:2, 3:5, :] = 0\n","            data[\"img\"][0:2, 3:5, 0] = 255\n","            data[\"img\"][3:5, 0:2, :] = 0\n","            data[\"img\"][3:5, 0:2, 1] = 255\n","            data[\"img\"][3:5, 3:5, :] = 0\n","            data[\"img\"][3:5, 3:5, 2] = 255\n","            data[\"img\"] = torch.tensor(data[\"img\"])\n","            data[\"label\"] = 0\n","        elif config[\"poison_type\"] == \"DBA\":\n","            # add backdoor pattern (3*3) to the image\n","            data[\"img\"] = np.array(data[\"img\"])\n","            # data[\"img\"] = add_pattern(data[\"img\"])\n","            global backdoor_idx\n","            if np.random.rand() < 0.4:\n","                if (backdoor_idx == 0 ):\n","                    data[\"img\"][0:2, 0:2, :] = 0\n","                if (backdoor_idx == 1):\n","                    data[\"img\"][0:2, 3:5, :] = 0\n","                    data[\"img\"][0:2, 3:5, 0] = 255\n","                if (backdoor_idx == 2):\n","                    data[\"img\"][3:5, 0:2, :] = 0\n","                    data[\"img\"][3:5, 0:2, 1] = 255\n","                if (backdoor_idx == 3):\n","                    data[\"img\"][3:5, 3:5, :] = 0\n","                    data[\"img\"][3:5, 3:5, 2] = 255\n","                data[\"img\"] = torch.tensor(data[\"img\"])\n","                # random flip 20% of the images label to 0\n","            \n","                data[\"label\"] = 0\n","        return data\n","\n","    def poisonTestData(data):\n","        # add backdoor pattern (5*5) to the image\n","        data[\"img\"] = np.array(data[\"img\"])\n","        data[\"img\"][0:2, 0:2, :] = 0\n","        data[\"img\"][0:2, 3:5, :] = 0\n","        data[\"img\"][0:2, 3:5, 0] = 255\n","        data[\"img\"][3:5, 0:2, :] = 0\n","        data[\"img\"][3:5, 0:2, 1] = 255\n","        data[\"img\"][3:5, 3:5, :] = 0\n","        data[\"img\"][3:5, 3:5, 2] = 255\n","        data[\"img\"] = torch.tensor(data[\"img\"])\n","        # print(data)\n","        return data\n","\n","    # Create train/val for each partition and wrap it into DataLoader\n","    trainloaders = []\n","    valloaders = []\n","    for partition_id in range(config[\"num_clients\"]):\n","        print(partition_id)\n","        partition = fds.load_partition(partition_id, \"train\")\n","        partition = partition.train_test_split(train_size=0.8, seed=config[\"seed\"])\n","        if(partition_id in config[\"poison_clients\"]):\n","            global backdoor_idx\n","            partition[\"train\"] = partition[\"train\"].map(poisonTrainData)\n","            backdoor_idx += 1\n","        partition[\"train\"] = partition[\"train\"].with_transform(apply_train_transforms)\n","        partition[\"test\"] = partition[\"test\"].with_transform(apply_val_transforms)\n","        trainloaders.append(DataLoader(partition[\"train\"], batch_size=config[\"batch_size\"]))\n","        valloaders.append(DataLoader(partition[\"test\"], batch_size=config[\"batch_size\"]))\n","    testData = fds.load_split(\"test\")\n","    if (config[\"poison_type\"] == \"DBA\" or config[\"poison_type\"] == \"CBA\") and len(config[\"poison_clients\"])!=0:\n","        testData = testData.map(poisonTestData)\n","    print(\"\\n------------------\\n\")\n","    testset = testData.with_transform(apply_val_transforms)\n","    testloader = DataLoader(testset, batch_size=config[\"batch_size\"])\n","\n","    return trainloaders, valloaders, testloader\n","\n","trainloaders, valloaders, testloader = load_datasets()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":464},"execution":{"iopub.execute_input":"2024-06-03T10:31:20.417049Z","iopub.status.busy":"2024-06-03T10:31:20.416760Z","iopub.status.idle":"2024-06-03T10:31:30.924546Z","shell.execute_reply":"2024-06-03T10:31:30.923561Z","shell.execute_reply.started":"2024-06-03T10:31:20.417006Z"},"id":"4nJXColRALJU","outputId":"2bc2eb48-e998-44f5-cb73-ab1e7360d771","trusted":true},"outputs":[],"source":["for i in range(5):\n","    if i==0:\n","        batch = next(iter(trainloaders[0]))\n","    elif i==1:\n","        batch = next(iter(trainloaders[1]))\n","    elif i==2:\n","        batch = next(iter(trainloaders[2]))\n","    elif i==3:\n","        batch = next(iter(trainloaders[3]))\n","    elif i==4:\n","        batch = next(iter(testloader))\n","    images, labels = batch[\"img\"], batch[\"label\"]\n","    # Reshape and convert images to a NumPy array\n","    # matplotlib requires images with the shape (height, width, 3)\n","    images = images.permute(0, 2, 3, 1).numpy()\n","    # Denormalize\n","    images = images / 2 + 0.5\n","\n","    # Create a figure and a grid of subplots\n","    fig, axs = plt.subplots(4, 8, figsize=(12, 6))\n","\n","    # Loop over the images and plot them\n","    for i, ax in enumerate(axs.flat):\n","        ax.imshow(images[i])\n","        ax.set_title(trainloaders[0].dataset.features[\"label\"].int2str([labels[i]])[0])\n","        ax.axis(\"off\")\n","\n","    # Show the plot\n","    fig.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T10:31:30.926310Z","iopub.status.busy":"2024-06-03T10:31:30.926004Z","iopub.status.idle":"2024-06-03T10:31:30.937014Z","shell.execute_reply":"2024-06-03T10:31:30.936203Z","shell.execute_reply.started":"2024-06-03T10:31:30.926284Z"},"id":"VFaUf5q8ARMs","trusted":true},"outputs":[],"source":["# class Net(nn.Module):\n","#     def __init__(self) -> None:\n","#         super(Net, self).__init__()\n","#         self.conv1 = nn.Conv2d(3, 8, 3)\n","#         self.pool = nn.MaxPool2d(2, 2)\n","#         self.conv2 = nn.Conv2d(8, 20, 5)\n","#         self.fc1 = nn.Linear(20 * 11 * 11, 256)\n","#         self.fc2 = nn.Linear(256, 128)\n","#         self.fc3 = nn.Linear(128, 32)\n","#         self.fc4 = nn.Linear(32, 10)\n","\n","#     def forward(self, x: torch.Tensor) -> torch.Tensor:\n","#         x = self.pool(F.relu(self.conv1(x)))\n","#         x = F.relu(self.conv2(x))\n","#         x = x.view(-1, 20 * 11 * 11)\n","#         x = F.relu(self.fc1(x))\n","#         x = F.relu(self.fc2(x))\n","#         x = F.relu(self.fc3(x))\n","#         x = self.fc4(x)\n","#         return x\n","\n","class Net(nn.Module):\n","    def __init__(self, p=0.1):\n","        super(Net, self).__init__()\n","\n","        ############################################\n","        # NOTE:                                    #\n","        # Pretrain weights on ResNet18 is allowed. #\n","        ############################################\n","\n","        # (batch_size, 3, 32, 32)\n","        self.p = p\n","        self.resnet = models.resnet18(weights=None)\n","        # (batch_size, 512)\n","        self.resnet.conv1 = nn.Conv2d(3, 64, kernel_size=2, stride=1, padding=1, bias=False)\n","        self.resnet.maxpool = Identity()\n","        self.resnet.fc = nn.Sequential(\n","            nn.Linear(self.resnet.fc.in_features, 128),\n","            nn.BatchNorm1d(128),\n","            nn.Dropout(self.p),\n","            nn.ReLU(True),\n","\n","            nn.Linear(128, 64),\n","            nn.BatchNorm1d(64),\n","            nn.Dropout(self.p),\n","            nn.ReLU(True),\n","\n","            nn.Linear(64, 32),\n","            nn.BatchNorm1d(32),\n","            nn.Dropout(self.p),\n","            nn.ReLU(True),\n","\n","            nn.Linear(32, 10),\n","        )\n","\n","    def forward(self, x):\n","        return self.resnet(x)\n","\n","class Identity(nn.Module):\n","    def __init__(self):\n","        super(Identity, self).__init__()\n","\n","    def forward(self, x):\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T10:31:30.939080Z","iopub.status.busy":"2024-06-03T10:31:30.938515Z","iopub.status.idle":"2024-06-03T10:31:30.978945Z","shell.execute_reply":"2024-06-03T10:31:30.977894Z","shell.execute_reply.started":"2024-06-03T10:31:30.939028Z"},"id":"KXXGXhB0AhEu","trusted":true},"outputs":[],"source":["def train(net, trainloader, epochs: int, verbose=False):\n","    \"\"\"Train the network on the training set.\"\"\"\n","    criterion = torch.nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(net.parameters())\n","    net.train()\n","    print(\"Training...\")\n","    for epoch in range(epochs):\n","        correct, total, epoch_loss = 0, 0, 0.0\n","        for batch in trainloader:\n","            images, labels = batch[\"img\"].to(DEVICE), batch[\"label\"].to(DEVICE)\n","            optimizer.zero_grad()\n","            outputs = net(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            # Metrics\n","            epoch_loss += loss\n","            total += labels.size(0)\n","            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n","        epoch_loss /= len(trainloader.dataset)\n","        epoch_acc = correct / total\n","        if verbose:\n","            print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n","\n","\n","def test(net, testloader):\n","    \"\"\"Evaluate the network on the entire test set.\"\"\"\n","    criterion = torch.nn.CrossEntropyLoss()\n","    correct, total, loss = 0, 0, 0.0\n","    net.eval()\n","    with torch.no_grad():\n","        for batch in testloader:\n","            images, labels = batch[\"img\"].to(DEVICE), batch[\"label\"].to(DEVICE)\n","            outputs = net(images)\n","            loss += criterion(outputs, labels).item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    loss /= len(testloader.dataset)\n","    accuracy = correct / total\n","    return loss, accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# trainloader = trainloaders[0]\n","# valloader = valloaders[0]\n","# net = Net().to(DEVICE)\n","\n","# for epoch in range(config[\"epochs\"]):\n","#     train(net, trainloader, 1)\n","#     loss, accuracy = test(net, valloader)\n","#     print(f\"Epoch {epoch+1}: validation loss {loss}, accuracy {accuracy}\")\n","\n","# loss, accuracy = test(net, testloader)\n","# print(f\"Final test set performance:\\n\\tloss {loss}\\n\\taccuracy {accuracy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T10:31:30.996348Z","iopub.status.busy":"2024-06-03T10:31:30.995999Z","iopub.status.idle":"2024-06-03T10:31:31.006830Z","shell.execute_reply":"2024-06-03T10:31:31.006011Z","shell.execute_reply.started":"2024-06-03T10:31:30.996318Z"},"id":"LNWfQImGBAae","trusted":true},"outputs":[],"source":["def set_parameters(net, parameters):\n","    # print(\"Setting parameters...\")\n","    state_dict = net.state_dict()\n","    params_dict = zip(state_dict.keys(), parameters)\n","\n","    # Check and print shapes for debugging\n","    for k, v in params_dict:\n","        expected_shape = state_dict[k].shape\n","        actual_shape = torch.tensor(v).shape\n","        # print(f\"Layer: {k} | Expected shape: {expected_shape} | Actual shape: {actual_shape}\")\n","\n","        if expected_shape != actual_shape:\n","            raise ValueError(f\"Shape mismatch for layer {k}: expected {expected_shape}, got {actual_shape}\")\n","\n","    # Re-create the zip iterator because it was exhausted during printing\n","    params_dict = zip(state_dict.keys(), parameters)\n","\n","    # Construct the new state_dict\n","    new_state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n","    net.load_state_dict(new_state_dict, strict=False)\n","\n","\n","def get_parameters(net) -> List[np.ndarray]:\n","    return [val.cpu().numpy() for _, val in net.state_dict().items()]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T10:31:31.010670Z","iopub.status.busy":"2024-06-03T10:31:31.010296Z","iopub.status.idle":"2024-06-03T10:31:31.025056Z","shell.execute_reply":"2024-06-03T10:31:31.024094Z","shell.execute_reply.started":"2024-06-03T10:31:31.010646Z"},"id":"e4lbmUq0A50O","trusted":true},"outputs":[],"source":["class FlowerClient(fl.client.NumPyClient):\n","    def __init__(self, net, cid, trainloader, valloader):\n","        self.net = net\n","        self.cid = cid\n","        self.trainloader = trainloader\n","        self.valloader = valloader\n","\n","    def get_parameters(self, config):\n","        return get_parameters(self.net)\n","\n","    def fit(self, parameters, local_config):\n","        # Read values from config\n","        server_round = local_config[\"server_round\"]\n","        local_epochs = 3 if self.cid in config[\"poison_clients\"] else local_config[\"local_epochs\"]\n","\n","        # Use values provided by the config\n","        print(f\"[Client {self.cid}, round {server_round}] fit, server_round: {server_round}, local_epochs: {local_epochs}\")\n","        set_parameters(self.net, parameters)\n","        copy_params = parameters.copy()\n","        train(self.net, self.trainloader, epochs=local_epochs)\n","        if self.cid in config[\"poison_clients\"]:\n","            #  set scale factor to 3.3 to scale up the malicious model weights.\n","            #Lt+1 = γ(X − Gt) + Gt\n","            new_params = []\n","            print(\"updating......\")\n","            new_params = get_parameters(self.net)\n","            \n","            for new_param, global_param in zip(new_params, copy_params):\n","                new_params.append(torch.tensor(config[\"gamma\"] * (new_param - global_param) + global_param))\n","            set_parameters(self.net, new_params)\n","        return get_parameters(self.net), len(self.trainloader), {}\n","\n","    def evaluate(self, parameters, config):\n","        # print(\"evaluating...\")\n","        set_parameters(self.net, parameters)\n","        # print(\"load\")\n","        loss, accuracy = test(self.net, self.valloader)\n","        # print(\"accuracy\")\n","        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T10:31:31.026605Z","iopub.status.busy":"2024-06-03T10:31:31.026241Z","iopub.status.idle":"2024-06-03T10:31:31.041663Z","shell.execute_reply":"2024-06-03T10:31:31.040630Z","shell.execute_reply.started":"2024-06-03T10:31:31.026558Z"},"id":"jTI0yZbBBCHc","trusted":true},"outputs":[],"source":["def client_fn(cid: str) -> FlowerClient:\n","    \"\"\"Create a Flower client representing a single organization.\"\"\"\n","\n","    # Load model\n","    net = Net().to(DEVICE)\n","    # Load data (CIFAR-10)\n","    # Note: each client gets a different trainloader/valloader, so each client\n","    # will train and evaluate on their own unique data\n","    trainloader = trainloaders[int(cid)]\n","    valloader = valloaders[int(cid)]\n","\n","    # Create a  single Flower client representing a single organization\n","    return FlowerClient(net, int(cid), trainloader, valloader).to_client()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T10:31:31.043313Z","iopub.status.busy":"2024-06-03T10:31:31.042930Z","iopub.status.idle":"2024-06-03T10:31:31.060557Z","shell.execute_reply":"2024-06-03T10:31:31.059595Z","shell.execute_reply.started":"2024-06-03T10:31:31.043282Z"},"id":"x8qQVld8BJdw","trusted":true},"outputs":[],"source":["def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n","    # Multiply accuracy of each client by number of examples used\n","    print(metrics)\n","    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n","    examples = [num_examples for num_examples, _ in metrics]\n","\n","    # Aggregate and return custom metric (weighted average)\n","    return {\"accuracy\": sum(accuracies) / sum(examples)}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T10:31:31.062109Z","iopub.status.busy":"2024-06-03T10:31:31.061791Z","iopub.status.idle":"2024-06-03T10:31:31.070395Z","shell.execute_reply":"2024-06-03T10:31:31.069380Z","shell.execute_reply.started":"2024-06-03T10:31:31.062078Z"},"id":"P0kTMnvC0P_D","trusted":true},"outputs":[],"source":["def fit_config(server_round: int):\n","    \"\"\"Return training configuration dict for each round.\n","\n","    Perform two rounds of training with one local epoch, increase to two local\n","    epochs afterwards.\n","    \"\"\"\n","    config = {\n","        \"server_round\": server_round,  # The current round of federated learning\n","        \"local_epochs\": 1\n","    }\n","    return config"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T10:31:31.071831Z","iopub.status.busy":"2024-06-03T10:31:31.071510Z","iopub.status.idle":"2024-06-03T10:31:31.082277Z","shell.execute_reply":"2024-06-03T10:31:31.081425Z","shell.execute_reply.started":"2024-06-03T10:31:31.071806Z"},"id":"VL4wvaJa0P_D","trusted":true},"outputs":[],"source":["# The `evaluate` function will be by Flower called after every round\n","results = []\n","def evaluate(\n","    server_round: int,\n","    parameters: fl.common.NDArrays,\n","    conf: Dict[str, fl.common.Scalar],\n",") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n","    net = Net().to(DEVICE)\n","    set_parameters(net, parameters)  # Update model with the latest parameters\n","    loss, accuracy = test(net, testloader)\n","    results.append(accuracy)\n","    if(server_round == config[\"epochs\"]):\n","        torch.save(net.state_dict(), \"final_model.pth\")\n","    print(f\"Server-side evaluation round {server_round}\")\n","    print(f\"Test set performance:\\n\\tloss {loss}\\n\\taccuracy {accuracy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from defense_method.krum import KrumServer\n","from defense_method.trim import TrimServer\n","from defense_method.bulyan import BulyanServer\n","from defense_method.qffl import QfflServer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-06-03T10:31:31.083978Z","iopub.status.busy":"2024-06-03T10:31:31.083541Z","iopub.status.idle":"2024-06-03T10:59:36.640622Z","shell.execute_reply":"2024-06-03T10:59:36.639452Z","shell.execute_reply.started":"2024-06-03T10:31:31.083945Z"},"id":"hpTqFDsrB_ky","outputId":"381485f7-0b5d-4c8a-acde-5b88b5bca15a","trusted":true},"outputs":[],"source":["# Create an instance of the model and get the parameters\n","net = Net().to(DEVICE)\n","if os.path.exists(\"final_model.pth\") and False:\n","    print(\"Loading model from final_model.pth\")\n","    net.load_state_dict(torch.load(\"final_model.pth\"))\n","params = get_parameters(net)\n","\n","\n","# Create FedAvg strategy\n","strategy = fl.server.strategy.FedAvg(\n","    fraction_fit=1.0,\n","    fraction_evaluate=0.5,\n","    min_fit_clients=config[\"num_clients\"],\n","    min_evaluate_clients=config[\"num_clients\"] // 2,\n","    min_available_clients=config[\"num_clients\"],\n","    evaluate_metrics_aggregation_fn=weighted_average,  # <-- pass the metric aggregation function\n","    evaluate_fn=evaluate,  # <-- pass the evaluation function\n","    on_fit_config_fn=fit_config,  # Pass the fit_config function\n","    initial_parameters=fl.common.ndarrays_to_parameters(params),\n",")\n","\n","# Specify the resources each of your clients need. By default, each\n","# client will be allocated 1x CPU and 0x GPUs\n","client_resources = {\"num_cpus\": 1, \"num_gpus\": 0.0}\n","if DEVICE.type == \"cuda\":\n","    # here we are assigning an entire GPU for each client.\n","    client_resources = {\"num_cpus\": 1, \"num_gpus\": 1.0}\n","    # Refer to our documentation for more details about Flower Simulations\n","    # and how to setup these `client_resources`.\n","\n","# Start simulation\n","fl.simulation.start_simulation(\n","    client_fn=client_fn,\n","    num_clients=config[\"num_clients\"],\n","    config=fl.server.ServerConfig(num_rounds=config[\"epochs\"],),\n","    strategy=strategy,\n","    client_resources=client_resources,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":527},"execution":{"iopub.execute_input":"2024-06-03T10:59:36.643177Z","iopub.status.busy":"2024-06-03T10:59:36.642581Z","iopub.status.idle":"2024-06-03T10:59:37.070925Z","shell.execute_reply":"2024-06-03T10:59:37.069940Z","shell.execute_reply.started":"2024-06-03T10:59:36.643144Z"},"id":"F2f7ySQ9yF_M","outputId":"7f3df829-6fd1-4df6-90b1-77f896020e6f","trusted":true},"outputs":[],"source":["# plot the results\n","plt.plot(results)\n","plt.xlabel(\"Round\")\n","plt.ylabel(\"Val Accuracy\")\n","plt.title(\"Validation Accuracy vs Rounds\")\n","plt.savefig(\"val_accuracy.png\")\n","\n","results = []"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T10:59:37.089125Z","iopub.status.busy":"2024-06-03T10:59:37.088848Z","iopub.status.idle":"2024-06-03T11:27:46.649926Z","shell.execute_reply":"2024-06-03T11:27:46.648737Z","shell.execute_reply.started":"2024-06-03T10:59:37.089102Z"},"trusted":true},"outputs":[],"source":["# Example usage of defense methods\n","# strategy = KrumServer(\n","#     num_malicious=config[\"poison_clients\"],\n","#     to_keep=config[\"num_clients\"] - len(config[\"poison_clients\"]),\n","#     fraction_fit=1.0,\n","#     fraction_evaluate=0.5,\n","#     min_fit_clients=config[\"num_clients\"],\n","#     min_evaluate_clients=config[\"num_clients\"] // 2,\n","#     min_available_clients=config[\"num_clients\"],\n","#     evaluate_metrics_aggregation_fn=weighted_average,  # <-- pass the metric aggregation function\n","#     evaluate_fn=evaluate,  # <-- pass the evaluation function\n","#     on_fit_config_fn=fit_config,  # Pass the fit_config function\n","#     initial_parameters=fl.common.ndarrays_to_parameters(params),\n","# )\n","\n","# strategy = Robust_Server(\n","#     fraction_fit=1.0,\n","#     fraction_evaluate=0.5,\n","#     min_fit_clients=config[\"num_clients\"],\n","#     min_evaluate_clients=config[\"num_clients\"] // 2,\n","#     min_available_clients=config[\"num_clients\"],\n","#     evaluate_metrics_aggregation_fn=weighted_average,  # <-- pass the metric aggregation function\n","#     evaluate_fn=evaluate,  # <-- pass the evaluation function\n","#     on_fit_config_fn=fit_config,  # Pass the fit_config function\n","#     initial_parameters=fl.common.ndarrays_to_parameters(params),\n","# )\n","\n","# # Start simulation\n","# fl.simulation.start_simulation(\n","#     client_fn=client_fn,\n","#     num_clients=config[\"num_clients\"],\n","#     config=fl.server.ServerConfig(num_rounds=config[\"epochs\"],),\n","#     strategy=strategy,\n","#     client_resources=client_resources,\n","# )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # plot the results\n","# plt.plot(results)\n","# plt.xlabel(\"Round\")\n","# plt.ylabel(\"Val Accuracy\")\n","# plt.title(\"Validation Accuracy vs Rounds\")\n","# plt.savefig(\"val_accuracy.png\")\n","\n","# results = []"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30716,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
